

services:
  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: finance-rag-api
    ports:
      - "8000:8000"
    volumes:
      # Mount data directory so embeddings persist
      - ./data:/app/data
      # Mount source for development (optional - remove for production)
      - ./src:/app/src
    environment:
      - PYTHONUNBUFFERED=1
      # Ollama runs on host machine, so we use host.docker.internal
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    extra_hosts:
      # Allow container to access host machine (for Ollama)
      - "host.docker.internal:host-gateway"
    networks:
      - rag-network
    restart: unless-stopped

  # Streamlit Frontend
  streamlit:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    container_name: finance-rag-streamlit
    ports:
      - "8501:8501"
    environment:
      - PYTHONUNBUFFERED=1
      # Point to API container
      - API_URL=http://api:8000
    depends_on:
      - api
    networks:
      - rag-network
    restart: unless-stopped

networks:
  rag-network:
    driver: bridge

